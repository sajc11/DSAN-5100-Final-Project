y = "Variables",
fill = "Correlation"
)
# Save the updated plot
ggsave("figures/consistent_decimal_correlation_heatmap.png", plot = heatmap, width = 10, height = 8)
# Display the heatmap inline
heatmap
# Inspect column names
colnames(data)
library(stringr)
library(ggplot2)
# Check if 'district' column exists
if (!"district" %in% colnames(data)) {
stop("The 'district' column is not found in the dataset.")
}
# Group Data by Borough
borough_comparison <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+")) %>%
group_by(borough) %>%
summarise(
avg_risk_score = mean(total_risk_score, na.rm = TRUE),
avg_vax_rate = mean(covid_vax_rate, na.rm = TRUE),
avg_death_rate = mean(covid_death_rate, na.rm = TRUE),
avg_uninsured = mean(percent_uninsured, na.rm = TRUE)
) %>%
arrange(desc(avg_risk_score))
# Ensure 'figures' directory exists
if (!dir.exists("figures")) {
dir.create("figures")
}
# Bar Chart for Average Risk Scores
borough_risk_plot <- ggplot(borough_comparison, aes(x = reorder(borough, avg_risk_score), y = avg_risk_score, fill = avg_risk_score)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average Risk Scores by Borough", x = "Borough", y = "Average Risk Score") +
coord_flip()
# Save the plot
ggsave("figures/borough_risk_scores.png", plot = borough_risk_plot, width = 8, height = 6)
# Display the plot inline
borough_risk_plot
# Additional Visualizations: Vaccination Rate by Borough
borough_vax_plot <- ggplot(borough_comparison, aes(x = reorder(borough, avg_vax_rate), y = avg_vax_rate, fill = avg_vax_rate)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average Vaccination Rates by Borough", x = "Borough", y = "Average Vaccination Rate") +
coord_flip()
# Save the vaccination rate plot
ggsave("figures/borough_vaccination_rates.png", plot = borough_vax_plot, width = 8, height = 6)
# Display plot inline
borough_vax_plot
# Additional Visualizations: Death Rate by Borough
borough_death_plot <- ggplot(borough_comparison, aes(x = reorder(borough, avg_death_rate), y = avg_death_rate, fill = avg_death_rate)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average Death Rates by Borough", x = "Borough", y = "Average Death Rate") +
coord_flip()
# Save the death rate plot
ggsave("figures/borough_death_rates.png", plot = borough_death_plot, width = 8, height = 6)
# Display plot inline
borough_death_plot
# Additional Visualizations: Uninsured Percent by Borough
borough_uninsured_plot <- ggplot(borough_comparison, aes(x = reorder(borough, avg_uninsured), y = avg_uninsured, fill = avg_uninsured)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average Uninsured Percent by Borough", x = "Borough", y = "Average Uninsured Percent") +
coord_flip()
# Save the uninsured percent plot
ggsave("figures/borough_uninsured_percent.png", plot = borough_uninsured_plot, width = 8, height = 6)
# Display plot inline
borough_uninsured_plot
data$uninsured_group <- cut(data$percent_uninsured, breaks = 3, labels = c("Low", "Medium", "High"))
anova_uninsured <- aov(total_risk_score ~ uninsured_group, data = data)
summary(anova_uninsured)
knitr::opts_chunk$set(echo = TRUE)
# Create 'figures' directory if it doesn't exist
if (!dir.exists("figures")) {
dir.create("figures")
}
library(ggplot2)
library(dplyr)
library(readr)
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Normalize the total risk score
data$total_risk_score <- data$total_risk_score / 36
str(data)
summary_stats <- data %>%
summarise(
mean_vax_rate = mean(covid_vax_rate, na.rm = TRUE),
median_vax_rate = median(covid_vax_rate, na.rm = TRUE),
var_vax_rate = var(covid_vax_rate, na.rm = TRUE),
mean_death_rate = mean(covid_death_rate, na.rm = TRUE),
median_death_rate = median(covid_death_rate, na.rm = TRUE),
var_death_rate = var(covid_death_rate, na.rm = TRUE),
mean_uninsured = mean(percent_uninsured, na.rm = TRUE),
median_uninsured = median(percent_uninsured, na.rm = TRUE),
var_uninsured = var(percent_uninsured, na.rm = TRUE)
)
summary_stats
# COVID-19 Vaccination Rates Distribution
vax_dist <- ggplot(data, aes(x = covid_vax_rate)) +
geom_histogram(binwidth = 0.05, fill = "blue", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribution of COVID-19 Vaccination Rates", x = "Vaccination Rate", y = "Frequency")
# Display plot inline
vax_dist
# save figures
ggsave("figures/vax_rate_dist.png", plot = vax_dist, width = 8, height = 6)
# COVID-19 Death Rates Distribution
death_dist <- ggplot(data, aes(x = covid_death_rate)) +
geom_histogram(binwidth = 0.001, fill = "red", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribution of COVID-19 Death Rates", x = "Death Rate", y = "Frequency")
# Display plot inline
death_dist
# save figures
ggsave("figures/death_rate_dist.png", plot = death_dist, width = 8, height = 6)
# Percent Uninsured Distribution
uninsured_dist <- ggplot(data, aes(x = percent_uninsured)) +
geom_histogram(binwidth = 0.01, fill = "green", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribution of Percent Uninsured", x = "Percent Uninsured", y = "Frequency")
# Display plot inline
uninsured_dist
# save figures
ggsave("figures/uninsured_dist.png", plot = uninsured_dist, width = 8, height = 6)
# Inspect column names
colnames(data)
# Vaccination Rate vs. Risk Score
vax_vs_risk <- ggplot(data, aes(x = covid_vax_rate, y = total_risk_score)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", col = "blue") +
theme_minimal() +
labs(title = "Vaccination Rate vs Risk Score", x = "Vaccination Rate", y = "Normalized Risk Score")
# Display plot inline
vax_vs_risk
# save figures
ggsave("figures/vax_vs_risk.png", plot = vax_vs_risk, width = 8, height = 6)
# Death Rate vs. Risk Score
death_vs_risk <- ggplot(data, aes(x = covid_death_rate, y = total_risk_score)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", col = "red") +
theme_minimal() +
labs(title = "Death Rate vs Risk Score", x = "Death Rate", y = "Normalized Risk Score")
# Display plot inline
death_vs_risk
# save figures
ggsave("figures/death_vs_risk.png", plot = death_vs_risk, width = 8, height = 6)
# Percent Uninsured vs. Risk Score
uninsured_vs_risk <- ggplot(data, aes(x = percent_uninsured, y = total_risk_score)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", col = "green") +
theme_minimal() +
labs(title = "Percent Uninsured vs Risk Score", x = "Percent Uninsured", y = "Normalized Risk Score")
# Display plot inline
uninsured_vs_risk
# save figures
ggsave("figures/uninsured_vs_risk.png", plot = uninsured_vs_risk, width = 8, height = 6)
median_vax_rate <- median(data$covid_vax_rate, na.rm = TRUE)
data$vax_group <- ifelse(data$covid_vax_rate > median_vax_rate, "Above Median", "Below Median")
t_test_vax <- t.test(total_risk_score ~ vax_group, data = data)
t_test_vax
library(ggplot2)
library(dplyr)
original_colnames <- colnames(data)
# Step 1: Compute correlation matrix and reshape
cor_matrix <- data %>%
select(where(is.numeric)) %>%
cor(method = "pearson", use = "pairwise.complete.obs")
cor_data <- as.data.frame(as.table(cor_matrix)) %>%
rename(Var1 = Var1, Var2 = Var2, Correlation = Freq) %>%
filter(Var1 != Var2)  # Remove diagonal (self-correlations)
# Debugging: Check the structure and head of `cor_data`
str(cor_data)
head(cor_data)
# Step 2: Filter for correlations > 0.5 (absolute value)
cor_data_filtered <- cor_data %>% filter(abs(Correlation) > 0.5)
# Debugging: Ensure filtered data is not empty
if (nrow(cor_data_filtered) == 0) {
stop("No correlations exceed the threshold of 0.5.")
}
# Step 3: Create a ggplot heatmap
heatmap <- ggplot(cor_data, aes(x = Var1, y = Var2, fill = Correlation)) +
geom_tile() +
geom_text(aes(label = sprintf("%.2f", Correlation)), size = 2.5) + # Ensure two decimals
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), space = "Lab") +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # Adjust font size and angle
axis.text.y = element_text(size = 8),
plot.title = element_text(size = 14, hjust = 0.5),
plot.subtitle = element_text(size = 10)
) +
labs(
title = "Correlation Heatmap of Public Health Metrics",
subtitle = "Pearson Method, Pairwise Complete Observations",
x = "Variables",
y = "Variables",
fill = "Correlation"
)
# Save the updated plot
ggsave("figures/consistent_decimal_correlation_heatmap.png", plot = heatmap, width = 10, height = 8)
# Display the heatmap inline
heatmap
source("~/.active-rstudio-document", echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Install and load libraries
install.packages("tidyverse")   # For data wrangling and visualization
install.packages("readr")       # For reading CSV files
install.packages("ggplot2")     # For plotting
library(tidyverse)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Load the cleaned dataset
data <- read_csv("./data/cleaned_housing_risk_data.csv")
# Load the cleaned dataset
data <- read_csv("/data/cleaned_housing_risk_data.csv")
setwd("~/DSAN 5100/DSAN_5100_Final")
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Install and load libraries
install.packages("tidyverse")   # For data wrangling and visualization
install.packages("readr")       # For reading CSV files
install.packages("ggplot2")     # For plotting
library(tidyverse)
library(readr)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(ggplot2)
library(tidyverse)
library(readr)
library(ggplot2)
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Normalize the total risk score
data$total_risk_score <- data$total_risk_score / 36
head(housing_data)
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Normalize the total risk score
data$total_risk_score <- data$total_risk_score / 36
head(data)
# Summary statistics for eviction and foreclosure rates
eviction_foreclosure_stats <- housing_data %>%
summarise(
mean_eviction_rate = mean(rate_eviction_filings, na.rm = TRUE),
median_eviction_rate = median(rate_eviction_filings, na.rm = TRUE),
mean_foreclosure_rate = mean(rate_forclosure_filings, na.rm = TRUE),
median_foreclosure_rate = median(rate_forclosure_filings, na.rm = TRUE)
)
# Summary statistics for eviction and foreclosure rates
eviction_foreclosure_stats <- data %>%
summarise(
mean_eviction_rate = mean(rate_eviction_filings, na.rm = TRUE),
median_eviction_rate = median(rate_eviction_filings, na.rm = TRUE),
mean_foreclosure_rate = mean(rate_forclosure_filings, na.rm = TRUE),
median_foreclosure_rate = median(rate_forclosure_filings, na.rm = TRUE)
)
# Print summary statistics
print(eviction_foreclosure_stats)
ggplot(data, aes(x = reorder(district, rate_eviction_filings), y = rate_eviction_filings, fill = rate_eviction_filings)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Eviction Rates by District",
x = "District",
y = "Eviction Rate"
)
ggplot(data, aes(x = reorder(district, rate_forclosure_filings), y = rate_forclosure_filings, fill = rate_forclosure_filings)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Foreclosure Rates by District",
x = "District",
y = "Foreclosure Rate"
)
ggplot(data, aes(x = rate_eviction_filings, y = rate_forclosure_filings)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
theme_minimal() +
labs(
title = "Eviction vs Foreclosure Rates",
x = "Eviction Rate",
y = "Foreclosure Rate"
)
housing_by_borough <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+")) %>%
group_by(borough) %>%
summarise(
avg_eviction_rate = mean(rate_eviction_filings, na.rm = TRUE),
avg_foreclosure_rate = mean(rate_forclosure_filings, na.rm = TRUE)
)
# Preview borough-level summary
print(housing_by_borough)
# Eviction Rates by Borough
ggplot(housing_by_borough, aes(x = reorder(borough, avg_eviction_rate), y = avg_eviction_rate, fill = avg_eviction_rate)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Average Eviction Rates by Borough",
x = "Borough",
y = "Eviction Rate"
)
# Foreclosure Rates by Borough
ggplot(housing_by_borough, aes(x = reorder(borough, avg_foreclosure_rate), y = avg_foreclosure_rate, fill = avg_foreclosure_rate)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Average Foreclosure Rates by Borough",
x = "Borough",
y = "Foreclosure Rate"
)
# Correlation matrix for housing-related variables
housing_correlation <- data %>%
select(rate_eviction_filings, rate_forclosure_filings, total_risk_score) %>%
cor(use = "pairwise.complete.obs")
# Print the correlation matrix
print(housing_correlation)
# Correlation matrix for housing-related variables
housing_correlation <- data %>%
select(rate_eviction_filings, rate_forclosure_filings, total_risk_score) %>%
cor(use = "pairwise.complete.obs")
# Print the correlation matrix
print(housing_correlation)
# Example: Divide eviction rates into categories
housing_data <- housing_data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Example: Divide eviction rates into categories
housing_data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Example: Eviction rate categories by borough
contingency_table <- table(data$eviction_rate_category, housing_data$borough)
# Example: Divide eviction rates into categories
data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Check if eviction_rate_category was created successfully
table(data$eviction_rate_category)
# Example: Eviction rate categories by borough
contingency_table <- table(data$eviction_rate_category, housing_data$borough)
# Example: Eviction rate categories by borough
contingency_table <- table(data$eviction_rate_category, data$borough)
# Example: Divide eviction rates into categories
data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Check if eviction_rate_category was created successfully
table(data$eviction_rate_category)
length(data$eviction_rate_category)
length(data$borough)
# Example: Eviction rate categories by borough
contingency_table <- table(data$eviction_rate_category, data$borough)
# Example: Divide eviction rates into categories
data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Check if eviction_rate_category was created successfully
table(data$eviction_rate_category)
data <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+"))
# Check unique borough values
print(unique(data$borough))
# Example: Divide eviction rates into categories
data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Check if eviction_rate_category was created successfully
table(data$eviction_rate_category)
data <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+"))
# Check unique borough values
print(unique(data$borough))
if (any(is.na(data$borough))) {
warning("Some rows in 'borough' column are missing.")
}
# Example: Divide eviction rates into categories
data <- data %>%
mutate(eviction_rate_category = cut(rate_eviction_filings,
breaks = c(-Inf, 0.02, 0.05, Inf),
labels = c("Low", "Medium", "High")))
# Check if eviction_rate_category was created successfully
table(data$eviction_rate_category)
data <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+"))
# Check unique borough values
print(unique(data$borough))
if (any(is.na(data$borough))) {
warning("Some rows in 'borough' column are missing.")
}
print(length(data$eviction_rate_category))
print(length(data$borough))
# Create the contingency table
contingency_table <- table(data$eviction_rate_category, data$borough)
print(contingency_table)
# Run the test if the contingency table has sufficient entries
if (all(dim(contingency_table) > 1)) {
chi_squared_test <- chisq.test(contingency_table)
print(chi_squared_test)
} else {
warning("Contingency table has insufficient data for Chi-Squared Test.")
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(ggplot2)
# Load the cleaned dataset
data <- read_csv("data/cleaned_housing_risk_data.csv")
# Normalize the total risk score
data$total_risk_score <- data$total_risk_score / 36
head(data)
# Summary statistics for eviction and foreclosure rates
eviction_foreclosure_stats <- data %>%
summarise(
mean_eviction_rate = mean(rate_eviction_filings, na.rm = TRUE),
median_eviction_rate = median(rate_eviction_filings, na.rm = TRUE),
mean_foreclosure_rate = mean(rate_forclosure_filings, na.rm = TRUE),
median_foreclosure_rate = median(rate_forclosure_filings, na.rm = TRUE)
)
# Print summary statistics
print(eviction_foreclosure_stats)
evic_dist <- ggplot(data, aes(x = reorder(district, rate_eviction_filings), y = rate_eviction_filings, fill = rate_eviction_filings)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Eviction Rates by District",
x = "District",
y = "Eviction Rate"
)
evic_dist
ggsave("figures/evic_dist.png", plot = evic_dist, width = 8, height = 6)
for_dist <- ggplot(data, aes(x = reorder(district, rate_forclosure_filings), y = rate_forclosure_filings, fill = rate_forclosure_filings)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_minimal() +
labs(
title = "Foreclosure Rates by District",
x = "District",
y = "Foreclosure Rate"
)
for_dist
ggsave("figures/for_dist.png", plot = for_dist, width = 8, height = 6)
corr_evic_for <- ggplot(data, aes(x = rate_eviction_filings, y = rate_forclosure_filings)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
theme_minimal() +
labs(
title = "Eviction vs Foreclosure Rates",
x = "Eviction Rate",
y = "Foreclosure Rate"
)
corr_evic_for
ggsave("figures/corr_evic_for.png", plot = corr_evic_for, width = 8, height = 6)
# Run the test given that the contingency table has sufficient entries - should work
if (all(dim(contingency_table) > 1)) {
chi_squared_test <- chisq.test(contingency_table)
print(chi_squared_test)
} else {
warning("Contingency table has insufficient data for Chi-Squared Test.")
}
# Example: Divide foreclosure rates into categories
data <- data %>%
mutate(foreclosure_rate_category = cut(rate_forclosure_filings,
breaks = c(-Inf, 0.005, 0.01, Inf),
labels = c("Low", "Medium", "High")))
# Check if foreclosure_rate_category was created successfully
table(data$foreclosure_rate_category)
# Check unique borough values
data <- data %>%
mutate(borough = str_extract(district, "^[A-Z]+"))
print(unique(data$borough))
# Create the contingency table for foreclosure rate categories by borough
contingency_table_foreclosure <- table(data$foreclosure_rate_category, data$borough)
print(contingency_table_foreclosure)
# Run the test given that the contingency table has sufficient entries
if (all(dim(contingency_table_foreclosure) > 1)) {
chi_squared_test_foreclosure <- chisq.test(contingency_table_foreclosure)
print(chi_squared_test_foreclosure)
} else {
warning("Contingency table has insufficient data for Chi-Squared Test.")
}
# View expected frequencies for the foreclosure rates
if (exists("chi_squared_test_foreclosure")) {
print(chi_squared_test_foreclosure$expected)
}
# Run Fisher's Exact Test for foreclosure rates (if necessary)
if (any(chi_squared_test_foreclosure$expected < 5)) {
fisher_test_foreclosure <- fisher.test(contingency_table_foreclosure)
print(fisher_test_foreclosure)
}
# Visualize the contingency table as a heatmap
ggplot(as.data.frame(as.table(contingency_table_foreclosure)), aes(x = Var2, y = Var1, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "red") +
theme_minimal() +
labs(title = "Foreclosure Rate Categories by Borough", x = "Borough", y = "Foreclosure Rate Category")
